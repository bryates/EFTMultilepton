import sys
import os
import glob
import subprocess
import argparse
import logging
import datetime

from EFTMultilepton.TemplateMakers.LvlFormatter import LvlFormatter

# A python script for generating the 'inputfiles__*.txt' files which are used to run the histogram
#   making part of the analysis workflow. The inputs should be root files generated by the analysis
#   tree maker. This acts as a replacement to the 'justmakefilelists.C' script.

TIMESTAMP1 = datetime.datetime.now().strftime('%Y_%m_%d')
TIMESTAMP2 = datetime.datetime.now().strftime('%Y%m%d_%H%M')
TIMESTAMP3 = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

USER_NAME = os.environ['USER']
USER_DIR = os.path.expanduser('~')
HOME_DIR = os.getcwd()
HADOOP_DIR = "/hadoop/store/user"

frmt = LvlFormatter()
logging.getLogger().setLevel(logging.DEBUG)

# Configure logging to also output to stdout
console = logging.StreamHandler()
console.setLevel(logging.INFO)
console.setFormatter(frmt)
logging.getLogger('').addHandler(console)

class Sample(object):
    def __init__(self,name,dirs=[]):
        self.__name = name
        self.__dirs = []
        for d in dirs: self.addDirectory(d)

    def name(self):
        return self.__name

    def list(self):
        return self.__dirs

    def addDirectory(self,*args):
        if len(args) == 0:
            return
        elif len(args) == 1:
            d = args[0]
        else:
            d = os.path.join(*args)
        if d in self.list():
            return
        self.__dirs.append(d)

# Still need to double check that these re-create the inputfiles verbatim
def legacy_geoff_samples():
    # Central signal samples
    # Note: There isn't a central tHq sample
    path = "gesmith/lobster_trees__EFT_test_27_2_19_central"
    ttZ_central = Sample('ttZ')
    ttZ_central.addDirectory(HADOOP_DIR,path,'ttZ')

    ttW_central = Sample('ttW')    
    ttW_central.addDirectory(HADOOP_DIR,path,'ttW')

    ttH_central = Sample('ttH')
    ttH_central.addDirectory(HADOOP_DIR,path,'ttH')

    path = "gesmith/lobster_trees__EFT_test_tZq_rmHiggs_8_7_19"
    tZq_central = Sample('tZq')
    tZq_central.addDirectory(HADOOP_DIR,path,'tZq')

    # Central bkgd samples
    path = "gesmith/lobster_trees__EFT_test_20_2_19_central_a"
    ttGJets_central = Sample('ttGJets')
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets')

    ZZZ_central = Sample('ZZZ')
    ZZZ_central.addDirectory(HADOOP_DIR,path,'ZZZ')

    WZZ_central = Sample('WZZ')
    WZZ_central.addDirectory(HADOOP_DIR,path,'WZZ')

    WZ_central = Sample('WZ')
    WZ_central.addDirectory(HADOOP_DIR,path,'WZ')
    
    WWZ_central = Sample('WWZ')
    WWZ_central.addDirectory(HADOOP_DIR,path,'WWZ')
    
    WWW_central = Sample('WWW')
    WWW_central.addDirectory(HADOOP_DIR,path,'WWW')

    path = "gesmith/lobster_trees__EFT_test_20_2_19_central_b"
    ZZ_central = Sample('ZZ')
    ZZ_central.addDirectory(HADOOP_DIR,path,'ZZ')
    
    WW_central = Sample('WW')
    WW_central.addDirectory(HADOOP_DIR,path,'WW')
    
    # Data samples
    path = "gesmith/lobster_trees__EFT_test_20_2_19_data_take2"
    SingleMuon_data = Sample('SingleMuon')
    SingleMuon_data.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017B')
    SingleMuon_data.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017C')
    SingleMuon_data.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017D')
    SingleMuon_data.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017E')
    SingleMuon_data.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017F')

    SingleElectron_data = Sample('SingleElectron')
    SingleElectron_data.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017B')
    SingleElectron_data.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017C')
    SingleElectron_data.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017D')
    SingleElectron_data.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017E')
    SingleElectron_data.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017F')

    MuonEG_data = Sample('MuonEG')
    MuonEG_data.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017B')
    MuonEG_data.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017C')
    MuonEG_data.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017D')
    MuonEG_data.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017E')
    MuonEG_data.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017F')

    DoubleMuon_data = Sample('DoubleMuon')
    DoubleMuon_data.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017B')
    DoubleMuon_data.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017C')
    DoubleMuon_data.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017D')
    DoubleMuon_data.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017E')
    DoubleMuon_data.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017F')

    DoubleEG_data = Sample('DoubleEG')
    DoubleEG_data.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017B')
    DoubleEG_data.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017C')
    DoubleEG_data.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017D')
    DoubleEG_data.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017E')
    DoubleEG_data.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017F')

    # Private EFT samples
    path = "gesmith/lobster_trees__EFT_test_EFTsamps_first_Round5_6_7_19"
    tllq_priv = Sample('tllq_multidim')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_batch1')
    
    ttlnu_priv = Sample('ttlnu_multidim')
    ttlnu_priv.addDirectory(HADOOP_DIR,path,'ttlnu_multidim_batch1')
    
    ttll_priv = Sample('ttll_multidim')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_batch1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_batch2')
    
    ttH_priv = Sample('ttH_multidim')
    ttH_priv.addDirectory(HADOOP_DIR,path,'ttH_multidim_batch1')

    tHq_priv = Sample('tHq_multidim')
    tHq_priv.addDirectory(HADOOP_DIR,path,'tHq_multidim_batch1')

    samples = [
        ttZ_central,
        ttW_central,
        ttH_central,
        tZq_central,

        ttGJets_central,
        ZZZ_central,
        WZZ_central,
        WZ_central,
        WWZ_central,
        WWW_central,
        ZZ_central,
        WW_central,

        SingleMuon_data,
        SingleElectron_data,
        MuonEG_data,
        DoubleMuon_data,
        DoubleEG_data,

        tllq_priv,
        ttlnu_priv,
        ttll_priv,
        ttH_priv,
        tHq_priv
    ]
    return samples

# 'Current' samples we want to use over the legacy geoff samples
def private_samples():
    ttH_priv   = Sample('ttH_multidim')
    tHq_priv   = Sample('tHq_multidim')
    tllq_priv  = Sample('tllq_multidim')
    ttll_priv  = Sample('ttll_multidim')
    ttlnu_priv = Sample('ttlnu_multidim')
    
    samples = []

    path = 'awightman/analysisTrees/private_sgnl_2019_10_09/v1'
    ttH_priv.addDirectory(HADOOP_DIR,path,'ttH_multidim_b1')
    tHq_priv.addDirectory(HADOOP_DIR,path,'tHq_multidim_b1')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b1')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b2')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b2')
    ttlnu_priv.addDirectory(HADOOP_DIR,path,'ttlnu_multidim_b1')

    samples.extend([tllq_priv,ttlnu_priv,ttll_priv,ttH_priv,tHq_priv])

    return samples

# MC based samples for anatest25
def anatest25_samples():
    ttZ_central = Sample('ttZ')
    ttW_central = Sample('ttW')    
    ttH_central = Sample('ttH')
    tZq_central = Sample('tZq')
    tHq_central = Sample('tHq')

    ttGJets_central = Sample('ttGJets')
    ZZZ_central = Sample('ZZZ')
    WZZ_central = Sample('WZZ')
    WWZ_central = Sample('WWZ')
    WWW_central = Sample('WWW')
    ZZ_central  = Sample('ZZ')
    WZ_central  = Sample('WZ')
    WW_central  = Sample('WW')

    ttH_priv   = Sample('ttH_multidim')
    tHq_priv   = Sample('tHq_multidim')
    ttll_priv  = Sample('ttll_multidim')
    tllq_priv  = Sample('tllq_multidim')
    ttlnu_priv = Sample('ttlnu_multidim')

    samples = []

    path = 'awightma/analysisTrees/central_sgnl_2019_10_11/v1'
    ttH_central.addDirectory(HADOOP_DIR,path,'ttH')
    tHq_central.addDirectory(HADOOP_DIR,path,'tHq')
    ttW_central.addDirectory(HADOOP_DIR,path,'ttW')
    ttZ_central.addDirectory(HADOOP_DIR,path,'ttZ')
    tZq_central.addDirectory(HADOOP_DIR,path,'tZq')

    samples.extend([ttH_central,tHq_central,ttW_central,ttZ_central,tZq_central])

    path = 'awightma/analysisTrees/central_bkgd_2019_10_12/v1'
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets')
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets_ext')
    ZZZ_central.addDirectory(HADOOP_DIR,path,'ZZZ')
    WZZ_central.addDirectory(HADOOP_DIR,path,'WZZ')
    WWZ_central.addDirectory(HADOOP_DIR,path,'WWZ')
    WWW_central.addDirectory(HADOOP_DIR,path,'WWW')
    ZZ_central.addDirectory(HADOOP_DIR,path,'ZZ')
    WZ_central.addDirectory(HADOOP_DIR,path,'WZ')
    WW_central.addDirectory(HADOOP_DIR,path,'WW')

    samples.extend([
        ttGJets_central,
        ZZZ_central,WZZ_central,WWZ_central,WWW_central,
        ZZ_central,WZ_central,WW_central
    ])

    path = 'awightma/analysisTrees/private_sgnl_2019_10_11/v1'
    ttH_priv.addDirectory(HADOOP_DIR,path,'ttH_multidim_b1')
    tHq_priv.addDirectory(HADOOP_DIR,path,'tHq_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b2')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b1')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b2')
    ttlnu_priv.addDirectory(HADOOP_DIR,path,'ttlnu_multidim_b1')
    
    samples.extend([ttH_priv,tHq_priv,ttll_priv,tllq_priv,ttlnu_priv])

    return samples

# MC based samples for anatest26
def anatest26_samples():
    ttZ_central = Sample('ttZ')
    ttW_central = Sample('ttW')    
    ttH_central = Sample('ttH')
    tZq_central = Sample('tZq')
    tHq_central = Sample('tHq')

    ttGJets_central = Sample('ttGJets')
    ZZZ_central = Sample('ZZZ')
    WZZ_central = Sample('WZZ')
    WWZ_central = Sample('WWZ')
    WWW_central = Sample('WWW')
    ZZ_central  = Sample('ZZ')
    WZ_central  = Sample('WZ')
    WW_central  = Sample('WW')

    ttH_priv   = Sample('ttH_multidim')
    tHq_priv   = Sample('tHq_multidim')
    ttll_priv  = Sample('ttll_multidim')
    tllq_priv  = Sample('tllq_multidim')
    ttlnu_priv = Sample('ttlnu_multidim')

    samples = []

    path = 'awightma/analysisTrees/central_sgnl_2019_10_11/v1'
    ttH_central.addDirectory(HADOOP_DIR,path,'ttH')
    tHq_central.addDirectory(HADOOP_DIR,path,'tHq')
    ttW_central.addDirectory(HADOOP_DIR,path,'ttW')
    ttZ_central.addDirectory(HADOOP_DIR,path,'ttZ')

    path = 'awightma/analysisTrees/central_bkgd_2019_10_12/v1'
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets')
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets_ext')
    ZZZ_central.addDirectory(HADOOP_DIR,path,'ZZZ')
    WZZ_central.addDirectory(HADOOP_DIR,path,'WZZ')
    WWZ_central.addDirectory(HADOOP_DIR,path,'WWZ')
    WWW_central.addDirectory(HADOOP_DIR,path,'WWW')
    ZZ_central.addDirectory(HADOOP_DIR,path,'ZZ')
    WZ_central.addDirectory(HADOOP_DIR,path,'WZ')
    WW_central.addDirectory(HADOOP_DIR,path,'WW')

    path = 'awightma/analysisTrees/private_sgnl_2019_10_11/v1'
    ttH_priv.addDirectory(HADOOP_DIR,path,'ttH_multidim_b1')
    tHq_priv.addDirectory(HADOOP_DIR,path,'tHq_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b2')
    ttlnu_priv.addDirectory(HADOOP_DIR,path,'ttlnu_multidim_b1')
    
    path = 'awightma/analysisTrees/special/tllq4f_2019_10_17_fixPDF/v1'
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b1')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b2')

    path = 'awightma/analysisTrees/special/tZq_2019_10_17_fixPDF/v2'
    tZq_central.addDirectory(HADOOP_DIR,path,'tZq')

    samples.extend([ttH_central,tHq_central,ttW_central,ttZ_central,tZq_central])
    samples.extend([
        ttGJets_central,
        ZZZ_central,WZZ_central,WWZ_central,WWW_central,
        ZZ_central,WZ_central,WW_central
    ])
    samples.extend([ttH_priv,tHq_priv,ttll_priv,tllq_priv,ttlnu_priv])

    return samples

# Re-processed data with new GT and updated some central samples to 'new_pmx'
def anatest27_samples():
    SingleElectron = Sample('SingleElectron')
    SingleMuon = Sample('SingleMuon')
    DoubleMuon = Sample('DoubleMuon')
    DoubleEG   = Sample('DoubleEG')
    MuonEG     = Sample('MuonEG')

    ttZ_central = Sample('ttZ')
    ttW_central = Sample('ttW')    
    ttH_central = Sample('ttH')
    tZq_central = Sample('tZq')
    tHq_central = Sample('tHq')

    ttGJets_central = Sample('ttGJets')
    ZZZ_central = Sample('ZZZ')
    WZZ_central = Sample('WZZ')
    WWZ_central = Sample('WWZ')
    WWW_central = Sample('WWW')
    ZZ_central  = Sample('ZZ')
    WZ_central  = Sample('WZ')
    WW_central  = Sample('WW')

    ttH_priv   = Sample('ttH_multidim')
    tHq_priv   = Sample('tHq_multidim')
    ttll_priv  = Sample('ttll_multidim')
    tllq_priv  = Sample('tllq_multidim')
    ttlnu_priv = Sample('ttlnu_multidim')

    samples = []

    # Data samples
    path = 'awightma/analysisTrees/data2017_2019_10_21/v1'
    SingleElectron.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017B')
    SingleElectron.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017C')
    SingleElectron.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017D')
    SingleElectron.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017E')
    SingleElectron.addDirectory(HADOOP_DIR,path,'SingleElectron_Run2017F')

    SingleMuon.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017B')
    SingleMuon.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017C')
    SingleMuon.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017D')
    SingleMuon.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017E')
    SingleMuon.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017F')
    # SingleMuon.addDirectory(HADOOP_DIR,path,'SingleMuon_Run2017H')    # Has no data

    DoubleMuon.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017B')
    DoubleMuon.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017C')
    DoubleMuon.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017D')
    DoubleMuon.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017E')
    DoubleMuon.addDirectory(HADOOP_DIR,path,'DoubleMuon_Run2017F')

    DoubleEG.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017B')
    DoubleEG.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017C')
    DoubleEG.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017D')
    DoubleEG.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017E')
    DoubleEG.addDirectory(HADOOP_DIR,path,'DoubleEG_Run2017F')

    MuonEG.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017B')
    MuonEG.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017C')
    MuonEG.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017D')
    MuonEG.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017E')
    MuonEG.addDirectory(HADOOP_DIR,path,'MuonEG_Run2017F')

    samples.extend([SingleElectron,SingleMuon,DoubleMuon,DoubleEG,MuonEG])

    # Updated to 'new_pmx' version (Note: The ttGJets sample failed horrifically)
    path = 'analysisTrees/special/central_ttH-WW-WZ-ttGJets_new_pmx_2019_10_21/v3'
    ttH_central.addDirectory(HADOOP_DIR,path,'ttH')
    WZ_central.addDirectory(HADOOP_DIR,path,'WZ')
    ZZ_central.addDirectory(HADOOP_DIR,path,'ZZ')

    samples.extend([ttH_central,WZ_central,ZZ_central])

    # Central samples (same as ana26)
    path = 'awightma/analysisTrees/central_sgnl_2019_10_11/v1'
    tHq_central.addDirectory(HADOOP_DIR,path,'tHq') # Excluding this from the list for now
    ttW_central.addDirectory(HADOOP_DIR,path,'ttW')
    ttZ_central.addDirectory(HADOOP_DIR,path,'ttZ')

    path = 'awightma/analysisTrees/special/tZq_2019_10_17_fixPDF/v2'
    tZq_central.addDirectory(HADOOP_DIR,path,'tZq')

    samples.extend([ttW_central,ttZ_central,tZq_central])

    path = 'awightma/analysisTrees/central_bkgd_2019_10_12/v1'
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets')
    ttGJets_central.addDirectory(HADOOP_DIR,path,'ttGJets_ext')
    ZZZ_central.addDirectory(HADOOP_DIR,path,'ZZZ')
    WZZ_central.addDirectory(HADOOP_DIR,path,'WZZ')
    WWZ_central.addDirectory(HADOOP_DIR,path,'WWZ')
    WWW_central.addDirectory(HADOOP_DIR,path,'WWW')
    WW_central.addDirectory(HADOOP_DIR,path,'WW')

    samples.extend([ttGJets_central,ZZZ_central,WZZ_central,WWZ_central,WWW_central,WW_central])

    # Private signal samples (same as ana26)
    path = 'awightma/analysisTrees/private_sgnl_2019_10_11/v1'
    ttH_priv.addDirectory(HADOOP_DIR,path,'ttH_multidim_b1')
    tHq_priv.addDirectory(HADOOP_DIR,path,'tHq_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b1')
    ttll_priv.addDirectory(HADOOP_DIR,path,'ttll_multidim_b2')
    ttlnu_priv.addDirectory(HADOOP_DIR,path,'ttlnu_multidim_b1')
    
    path = 'awightma/analysisTrees/special/tllq4f_2019_10_17_fixPDF/v1'
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b1')
    tllq_priv.addDirectory(HADOOP_DIR,path,'tllq_multidim_b2')

    samples.extend([ttH_priv,tHq_priv,ttll_priv,ttlnu_priv,tllq_priv])

    return samples

def main():
    out_dir = '.'
    log_file = os.path.join(out_dir,'out.log')
    outlog = logging.FileHandler(filename=log_file,mode='w')
    outlog.setLevel(logging.DEBUG)
    outlog.setFormatter(frmt)
    logging.getLogger('').addHandler(outlog)

    logging.info("Start: {tstamp}".format(tstamp=TIMESTAMP3))

    # samples = private_samples()
    # samples = legacy_geoff_samples()
    # samples = anatest25_samples()
    # samples = anatest26_samples()
    samples = anatest27_samples()

    for s in samples:
        outf = 'inputfiles__{name}.txt'.format(name=s.name())
        logging.info("Making file: {fn}".format(fn=outf))
        lst = []
        for tdir in s.list():
            if not os.path.exists(tdir):
                continue
            logging.info("Adding files from {dir}".format(dir=tdir))
            for fn in os.listdir(tdir):
                fpath = os.path.join(tdir,fn)
                if not os.path.isfile(fpath):
                    continue
                h,t = fn.rsplit('.',1)
                if t == 'root':
                    lst.append(fpath)
        logging.info("Found files: {0:d}".format(len(lst)))
        with open(outf,'w') as f:
            for fpath in lst:
                f.write(fpath+"\n")
    logging.info("Finished!")

if __name__ == "__main__":
    main()